\documentclass{scrartcl}

\usepackage{listings}
\usepackage{tabularx}
\usepackage{ragged2e}

\newcolumntype{Y}{>{\RaggedRight\arraybackslash}X} 

\makeindex

\begin{document}
    \title{The Pixy programming language}
    \subtitle{An alternate approach to realtime and concurrent Lucid}
    \author{A. Finn Hackett, Reed Mullanix}
    
    \maketitle

    \tableofcontents

    \section{Introduction}

    Pixy is a dataflow language based on Lucid, a dataflow programming language that was initially developed throughout the 70s and 80s with the goal of expressing complex algorithms in clear, mathematically coherent statements. Unlike other approaches to this problem which are based on the lambda calculus and are centered around function definition and application, Lucid based itself on an infinitary algebra, allowing programmers to directly define and manipulate streams of data with implicit iteration.

    Derivative work has taken Lucid in various directions, one significant one being Lucid's apparent suitability for fine-grained concurrency and realtime systems. Two cases in particular are SISAL and RLucid which considered fine-grained concurrency and adaptations of Lucid to realtime computation respectively.
    
    We propose an alternative approach to adapting Lucid to realtime systems programming that combines flexible support for application-controlled approaches to concurrency and data rate synchronisation with an attempt at using a more powerful notion of temporal typing than RLucid to verify the temporal consistency of data streams without any implicit buffering.
    
    Our main practical goal is to be able to support verified compilation of dataflow networks with heterogenous flow rates such as realtime audio processing applications with GUIs or network/hardware control inputs, such that Pixy is capable of expressing both the internal computations and the interactions between each of the modules.

    Specifically, we hope to investigate the following:
    \begin{enumerate}
        \item In order to support realtime operation, modifications to the language semantics such that programs can be guaranteed to run with a constant memory footprint unless it is specifically and clearly chosen otherwise
        \item Typechecking for stream values and flow rate consistency, including arbitrary regular patterns
        \item Compilation strategies that support both of the above
    \end{enumerate}

    \section{Evaluation}

    Our proposed approach to Pixy's evaluation semantics is based on some alternate perspectives on how Lucid can be evaluated. The usual explanation for how Lucid is evaluated involves dataflow graphs and on-demand semantics, but this was built with dataflow machines in mind and does not map well to modern consumer computer architectures.

    We instead propose to view Lucid's existing semantics as state machine definitions, where state is an assignment to all the variables in the current context. A Pixy expression therefore defines a state space, an initial state and a transition function that produces the next state. In essence, the basic units of which Pixy is comprised are deterministic finite automata.
    
    \subsection{Representing when a stream does not yield a value}
    
    As it stands the state machine evaluation strategy has a clear limitation - it requires all streams to synchronously produce values. This is not only unhelpful in view of supporting concurrency with heterogenous flow rates, but also flawed in that it cannot correctly express the evaluation of an expression such as $\textbf{next}\ 1$. At state 0 this expression has no value. It is only at state 1 that it gains the value $1$.
    
    Our current strategy for representing such cases is to invent an empty stream $\textbf{nil}$ similar to hiatons as discussed in the Lucid book. It represents the absence of value, such that a representation of $\textbf{next}\ 1$ as an infinite list would be $\{\textbf{nil}, 1, ...\}$.
    
    \subsection{What to do when a stream does not yield a value}
    
    \label{subsec:async}
    
    Since we do not want to include implicit buffering in Pixy's semantics, dealing with streams that have no value becomes an interesting exercise. Simple arithmetic operations easily become problematic when one operand holds the value $\textbf{nil}$ but the other does not. This has to be an error since waiting for the $\textbf{nil}$ to go away will lose the other value, and trying to add $\textbf{nil}$ to anything has no meaningful definition.
    
    Our proposed solution to this is to allow user code to check whether a stream has a value at the current timestep using the operator $?$. This combined with custom logic can be used to ensure that any operations that require synchronous operands will always receive all the values they require or none of them.
    
    For example, here is a synchronisation operation that takes two streams that are not properly synchronised and ensures that they are using statically sized buffers, yielding either $(\textbf{nil}, \textbf{nil})$ or a tuple of the values.
    
    For simplicity, this example assumes simple queue ADT operations have been defined.
    \footnote{see Appendix \ref{app:queueops} for API reference}
    
    \begin{lstlisting}
buffer(srcA, srcB) = (syncA, syncB) where
    haveValues = !emptyQueue(queueA) && !emptyQueue(queueB);
    manageQueue(queue, input) = (queuePushed, poppedValue) where
        (queuePopped, poppedValue) = if haveValues then
            popFromQueue(queue)
        else
            (queue, nil)
        fi;
        queuePushed = if ?input && !fullQueue(queuePopped) then
            -- discard input if queue is full, could also
            -- increase queue size depending on application
            -- requirements
            pushToQueue(queuePopped, input)
        else
            queuePopped
        fi;
    end;
    (queueA, syncA) = (makeQueue!(N), nil) fby
        manageQueue(queueA, srcA);
    (queueB, syncB) = (makeQueue!(N), nul) fby
        manageQueue(queueB, srcB);
end
    \end{lstlisting}
        
    \subsection{Representing when a stream cannot yield a value}
    
    Aside from cases where a stream does not immediately yield a value, the opposite case where the last value has not yet been processed but a new value is available can occur. This can happen for one of three reasons:
    \begin{itemize}
        \item the same value is required at different times - this is an invalid Lucid program; all values must be required only once
        \item the stream in question represents an external source of some kind
        \item the stream in question is being used as input for an external I/O sink
    \end{itemize}
    
    The first case is simple: this is an error.
    
    In the second case, the external interface must wait or be buffered
    
    In the third case, the Lucid stream must wait. Care should be taken in the type system and verification to ensure such waiting is handled correctly - there may be extra synchronisation primitives necessary in some cases.
    
    At some point in the future it may be interesting to construct communication primitives for Pixy but at this stage we will not consider this in much detail.

    \subsection{Problems with recursive definitions}
    
    Natural recursion in Pixy is problematic from a memory management point of view. Recursion either uses unbounded memory via callstack growth or is tail recursion. Since unbounded non-tail call recursion implies unbounded memory growth it is not desirable for Pixy.
    
    In principle Pixy could just only accept tail-call recursion, but there is a much simpler way to achieve this.
    
    Let us take an example from the Lucid book, a definition of operator \textbf{asa} that uses tail recursion.
    \begin{lstlisting}
asa(x, y) = if first y then first x else asa(next x, next y) fi
    \end{lstlisting}
    
    Using $\textbf{nil}$ this can be easily implemented without any recursion:
    \begin{lstlisting}
asa(x, y) = if y then x else nil fi
    \end{lstlisting}
    
    Another avenue to consider for cases of bounded recursion is implementing inductive types. These could then be used to termination analysis, resulting in arbitrary recursion with a known depth. Since the recursion we are considering here can be imagined to occur at "setup time" rather than generally at runtime, this would allow a much broader range of constructs while preserving the constant memory requirement by preallocating memory up to the determined recursion depth.
    
    \subsection{Dealing with Turing-completeness and memory management}
    
    Defining Pixy expressions as deterministic finite automata is useful in that:
    \begin{itemize}
        \item It enforces constant memory operation at the semantic level
        \item Analysis of any Pixy expression following these constraints is decideable
    \end{itemize}
    
    This is however a significant limitation in terms of computing power. While we suggest most Lucid code can be expressed using only as much computational power as a DFA, it is important in general-purspose computation that the programmer to be able to express unbounded memory usage if they so choose.
    
    To resolve this we propose the $\textbf{alloc!}$ and $\textbf{free!}$ primitives. These primitives would allow the programmer to define a state machine of variable size and assign it to a variable. To ensure that only alloc! is capable of causing memory allocation, values produced by this primitive can only be moved not copied. To prevent memory leaks, values produced by $\textbf{alloc!}$ must either be moved, consumed by $\textbf{free!}$ or local to a particular custom operator.
    
    The new state machine can be connected to an existing program by calling it like a user-defined transformation.
    
    \begin{equation}
    \textbf{alloc!} (\textnormal{args}...) => \textnormal{expression}
    \end{equation}
    
    \begin{equation}    
    \textbf{free!} \textnormal{to\_free}... | \textnormal{expression}
    \end{equation}
    
    Unlike the rest of Pixy as it stands, since this construct strays outside of the domain of finite state machines we must reason about it very carefully. While complete analysis of this construct is not possible, we want to retain as much analysability as possible.
    
    There are a few cases we can trivially rule out as using a constant amount of memory and therefore still representable within finite state machines:
    \begin{itemize}
        \item The left-hand side of a top-level \textbf{fby}, as this merely states the initial value of a variable and does not influence dataflow otherwise
        \item Expressions that merely use the resulting value without allocating or deallocating anything
        \item \textbf{free!} can be modeled as a no-op, as calling it is merely a matter of leak-safety and not semantics
    \end{itemize}
    
    This leaves us with any other usage of \textbf{alloc!}. A proposed conservative model of this operation is to consider what it really entails: a handle to another state machine is generated. At this stage the parameters and their timings are unknown. As a result, naively speaking nothing can be known about the outputs of the state machine either without full-program analysis.
    
    Considering the result of \textbf{alloc!} as an opaque handle with completely unknown timings may be all that is possible in some cases, and as a result inputs and outputs would have to be strictly synchronised both on the machine's inputs and outputs.
    
    There are perhaps some happy paths that can be considered however: allowing the programmer to annotate expectations regarding inputs and outputs of the resulting state machine would make checking assumptions within the bounds of those annotations. It may also be possible to conservatively observe some properties of resulting state machines if they are simple enough.
    
    There may be some cases where this construct could harm optimisation and analysis opportunities, but this is correct. If an assumption is not stated and cannot be derived then either the rest of the code has to account for this or further assumptions must be stated.

    \section{Efficiency via deterministic finite automata}
    
    \label{sec:efficiency}
    
    Many optimising compilers must look for gaps in the language semantics that they can use in order to generate more efficient code. Compilers for Haskell and other languages that offer referential transparency and lazy evaluation are a good example of this. They can perform powerful program transformations that skip entire execution paths, simply because the semantics allow this. It is also possible in general to detect and take shortcuts around values known to be constant, or in more dynamic languages to speculatively guess dynamic values and fall back if that guess is wrong.
    
    Pixy's representability as one or more DFAs (in the case of \textbf{alloc!} usage) suggests a fully general optimisation tool: DFA minimization. Using an established minimization algorithm such as Hopcroft's algorithm a Pixy compiler might be able to easily perform  full-program simplification.
    
    The key obstacle to this being useful lies in finding a compact DFA representation of a Pixy program's state. A naive transformation of a Pixy program using one byte of memory would generate a DFA that has 256 states, which would grow exponentially with program memory usage. A small system utility for example might take 16kb of memory, which would lead to a state space the size of which is 4817 digits long.
    
    Some possibilities for pruning such a state space likely lie in abstracting out control flow. Relatively few values in memory have an effect on control flow, so such a representation may be much more proportional to actual program complexity.
    
    This proposal suggests that good compressed state machine representations may be derived using an analoguous mechanism to that used in section \ref{sec:temporaltypesystem}.
    
    \section{A temporal type system}
    
    \label{sec:temporaltypesystem}
    
    We propose a typing scheme for Pixy that attempts to eliminate 2 classes of errors: value compatibility and temporal compatibility.
    
    One of the biggest issues we have forseen is the synchronisation of streams that produce at different rates. As discussed in section \ref{subsec:async}, programmers may be required to explicitly use synchronisation primitives in order to ensure that operations that expect synchronous data are treated correctly. This raises the question: how does one detect whether or not an operator is being passed a compatible stream?
    
    Our proposed approach is give expressions a second type - a temporal type. This type would be a compressed representation of the externally visible control flow in an expression, and would be composable via further control flow.
    
    For example, consider this toy program:
    \begin{lstlisting}
v where
    flag = false fby !flag;
    foo = if flag then 1 else nil fi;
    bar = if !flag then 2 else nil fi;
    v = if ?foo then foo else bar;
end
    \end{lstlisting}
    
    A reader might notice that $v$ represents the infinite sequence $\{2,1,2,1,2,1,\dots\}$. In order to prove, for example, that $v + \textbf{next} v$ will not fail at runtime, the type system must also know this.
    
    As a reader may also notice, observing this pattern requires the type system to know the values of streams. This means that any type system for Pixy must be dependent. Given Pixy can be modeled by one or more DFAs, perhaps such a type system would yield an algebra over DFA composition.
    
    \section{Conclusion and deliverables}

    In conclusion, we propose to refine the insight we have already gained from developing this proposal into:
    \begin{itemize}
        \item A precise formal description of semantics of the programming language we refer to as ``Pixy"
        \item A dependent type system based on the composition of DFAs that verifies stream synchronisation in Pixy
        \item A naive compiler for Pixy that exercises the above (based on LLVM)
        \item In the unlikely event that time permits, an optimising compiler based on ideas from section \ref{sec:efficiency}
    \end{itemize}

    \appendix

    \section{Appendix: Queue operation definitions}
    \label{app:queueops}

    \begin{tabularx}{\textwidth}{ @{} r | Y @{} }
        $\textnormal{emptyQueue}(\textnormal{queue}) => \textnormal{bool}$ & returns true if the queue is empty. \\
        $\textnormal{fullQueue}(\textnormal{queue}) => \textnormal{bool}$ & returns true if the queue cannot store any more elements. \\
        $\textnormal{makeQueue!}(\textnormal{n}) => \textnormal{queue}$ & returns a bounded queue of size n. \\
        $\textnormal{pushToQueue}(\textnormal{queue}, \textnormal{val}) => \textnormal{queue}'$ & returns a queue queue' that is the result of adding val to queue. Requires $!\textnormal{fullQueue}(\textnormal{queue})$. \\
        $\textnormal{popFromQueue}(\textnormal{queue}) => (\textnormal{queue}', \textnormal{val})$ & returns pair where queue' is the result of popping val from queue.
    \end{tabularx}

\end{document}
